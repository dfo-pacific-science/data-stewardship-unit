{
  "hash": "bace899f748b13bfc47eea35754bb41d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Accessing Spatial Data from the Open Government Portal\"\nformat: html\nversion: \"v1.0\"\nlast_updated: \"2025-08-11\"\nexecute:\n  eval: false\n---\n\n\n\n\n## Background\n\nThis tutorial provides an overview for how to extract spatial data from the [Open Government Portal](https://open.canada.ca/), commonly referred to as *Open Data*. OGP is the Government of Canada's official platform for publishing federal datasets, and DFO Science staff publish eligible data products there to meet open data policy requirements, ensure visibility of our work, and support reuse by partners and the public.\n\nThe code below shows how to leverage the resources available on OGP, making it easier to meet FAIR (Findable, Accessible, Interoperable, Reusable) principles and support reproducible science.\n\nThis tutorial reviews:\n\n-   Querying ArcGIS REST services\n\n-   Extracting data from file geodatabases\n\n-   Using `ckanr` to build more robust code\n\nThe examples cover the basics of mapping in R, including plotting both vector and raster data with `ggplot()`, and creating `leaflet` maps. Many online tutorials provide further detail for specifics of mapping in R if you need more background. For example, [this tutorial from the University of Toronto](https://mdl.library.utoronto.ca/technology/tutorials/introduction-gis-using-r) provides a very good overview.\n\nNote that much of this content has been expanded from a [similar tutorial created in the DFO Maritimes Region](https://github.com/AtlanticR/R_Git_Support/blob/main/open_data.Rmd), but with DFO Pacific examples. Other clarifying comments have also been added.\n\n### Loading packages\n\nThe [librarian](https://cran.r-project.org/web/packages/librarian/vignettes/intro-to-librarian.html) package is useful for loading multiple packages in R. It allows you to load packages from CRAN, GitHub, and other sources with a single command. It also installs missing packages automatically.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set CRAN mirror to avoid errors\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\n# Install librarian if not already installed\nif (!requireNamespace(\"librarian\", quietly = TRUE)) {\n  install.packages(\"librarian\")\n}\n\n# Load packages using librarian\nlibrarian::shelf(\n  arcpullr, ckanr, dplyr, devtools, ggplot2, ggspatial, leaflet, leafpop, mapview,\n  rnaturalearth, sf, stars, terra, viridisLite, ropensci/rnaturalearthhires # example for loading from GitHub\n)\n```\n:::\n\n\n\n\n## Accessing Open Data via ARCGIS REST\n\nThe `arcpullr` package is a great way to access [ArcGIS REST services](https://geoappext.nrcan.gc.ca/arcgis/sdk/rest/index.html#//02ss00000057000000), which are often used for storing spatial data on Open Data. You can use the `get_spatial_layer()` function to retrieve a spatial layer from an ArcGIS server.\n\n### Example: Pacific Recreational Fishery Salmon Head Depots\n\nThere can many URLs associated with each dataset. The \"ArcGIS Rest URL\" we need to feed into the `get_spatial_layer()` function should be the one that includes \"arcgis/rest/services\".\n\nFor example, with the [Pacific Recreational Fishery Salmon Head dataset](https://open.canada.ca/data/en/dataset/3cc03bbf-d59f-4812-996e-ddc52e0ba99e), the URL we are interested in is <https://egisp.dfo-mpo.gc.ca/arcgis/rest/services/open_data_donnees_ouvertes/pacific_recreational_fishery_salmon_head_depots/MapServer/>.\n\nIf you have trouble tracking this down, go to the appropriate [dataset page](https://open.canada.ca/data/en/dataset/3cc03bbf-d59f-4812-996e-ddc52e0ba99e) on Open Data.\n\nThen, under the **Data and Resources** section, find the item labelled **ESRI REST** (there is both an English and French example). Left click on the **Explore** dropdown item, then right click on **Go to resource**, and then left click on **Copy link**. This then copies the link to the URL you need.\n\n![goToResource](../images/openDataSpatial/geodatabaseLink.png)\n\nIt is important to ensure the appropriate layer is specified. In this example, the \"0\" at the end of the address denotes the English version, while a 1 represents French (see layers within the [MapServer page](https://egisp.dfo-mpo.gc.ca/arcgis/rest/services/open_data_donnees_ouvertes/pacific_recreational_fishery_salmon_head_depots/MapServer)). They also do not always correspond to language. For example, in the [Pacific Commercial Salmon In Season Catch Estimates dataset](https://egisp.dfo-mpo.gc.ca/arcgis/rest/services/open_data_donnees_ouvertes/pacific_commercial_salmon_in_season_catch_estimates_en/MapServer), layers 0 to 3 represent gill nets, troll, seine and Pacific Fishery Management Areas, respectively.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsalmonDepots = get_spatial_layer(\"https://egisp.dfo-mpo.gc.ca/arcgis/rest/services/open_data_donnees_ouvertes/pacific_recreational_fishery_salmon_head_depots/MapServer/0\")\n```\n:::\n\n\n\n\n### Creating a map\n\nThere are some great packages to get basemaps in R. The `rnaturalearth` package is a good option for getting country borders and other geographical features. You can use the `ne_countries()` function to get country borders.\n\nIn British Columbia, `rnaturalearth` may not have the level of detail required (e.g., some islands are missing). The `bcmaps` package has a lot of detailed basemaps and spatial data for the BC coast, and the `bc_bound_hres()` function is particularly useful for mapping coastline.\n\nSince the data used in the tutorial are for the entire BC coast, `rnaturalearth` is used in the examples below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get coastline for North America \ncoast = ne_countries(scale = 10, returnclass = c(\"sf\"), continent = \"North America\") \n```\n:::\n\n\n\n\nBecause the coastline basemap data span all of North America, it may be useful to crop the plot to the bounding box of the data (BC coast). The `st_bbox()` function from the `sf` package allows you to get the bounding box of a spatial object. You can use the `xlim` and `ylim` arguments in the `coord_sf()` function to set the limits of the x and y axes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define lat/lon bounds of your dataset\nbounds = st_bbox(salmonDepots)\n\nggplot()+\n  geom_sf(data = coast, fill = \"lightgrey\")+\n  geom_sf(data = salmonDepots, size = 3.5, aes(fill = ACCESSIBILITY___ACCESSIBILITÃ‰), pch = 21, alpha = 0.85)+\n  coord_sf(xlim = c(bounds[\"xmin\"], bounds[\"xmax\"]),\n    ylim = c(bounds[\"ymin\"], bounds[\"ymax\"]))+\n  # I'm not always convinced maps north arrows need to be added when the lat/lon is specified but some people insist!\n  # Add north arrow to the top right (tr) of the map. It points to \"true\" north, not magnetic north\n  annotation_north_arrow(location = \"tr\", which_north = \"true\",\n                         #height = unit(0.7, \"cm\"), width = unit(0.7, \"cm\"),\n                         style = north_arrow_minimal)+\n  # Also, scale bars shouldn't be added when you're this zoomed out, but here's how to add one anyway to the bottom left (bl):\n  annotation_scale(location = \"bl\", text_cex = 0.8)+\n  scale_fill_discrete(name = \"Accessibility\")+\n  theme_bw() # tidies up the visuals \n```\n:::\n\n\n\n\n## Accessing file geodatabases\n\n[File geodatabases](https://pro.arcgis.com/en/pro-app/latest/help/data/geodatabases/manage-file-gdb/file-geodatabases.htm) are a proprietary file format developed by ESRI for spatial and non-spatial data. Many spatial datasets are uploaded to Open Data as file geodatabases, and it is possible to download and extract them with R!\n\nThe example below shows how to access the file geodatabase from the [floating infrastructure dataset on Open Data](https://open.canada.ca/data/en/dataset/049770ef-6cb3-44ee-afc8-5d77d6200a12)\n\n### Creating temporary directories\n\nFor exploring data, it is often helpful to create temporary directories to store and extract data. This can be easier than downloading the data directly and setting your directories.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a temporary directory to store the downloaded zip file\ntemp_dir = tempdir()\n\n# Define the path for the downloaded zip file inside the temp directory\nzip_file = file.path(temp_dir, \"zipPath.gdb.zip\")\n\n# Define the directory where the zip contents will be extracted\n# This is a relative path, so files will be extracted into the current working directory\nunzip_dir = file.path(\"extracted_fgdb\")\n\n# Download the dataset zip file. To get the correct link, follow the same steps as in the Pacific Recreational Fishery Salmon Head Depots example above, but with the \"FDGB/GDB\" item in Data and resources \ndownload.file(\n  \"https://api-proxy.edh-cde.dfo-mpo.gc.ca/catalogue/records/049770ef-6cb3-44ee-afc8-5d77d6200a12/attachments/floating_infrastructure-docks.gdb.zip\",\n  destfile = zip_file,\n  mode = \"wb\"\n)\n\n# Create the extraction directory if it doesn't already exist\ndir.create(unzip_dir, showWarnings = FALSE)\n\n# Unzip the downloaded file into the extraction directory\nunzip(zip_file, exdir = unzip_dir)\n\n# List the files extracted to verify contents\nlist.files(unzip_dir)\n\n# Load the layers available in the extracted .gdb file\n# Copy the name from the list.files() command. This should match the name of the gdb from the URL above\nlayers = st_layers(file.path(unzip_dir, \"floating_infrastructure-docks.gdb\"))\n\n# Turn layers from a list into a dataframe\n# layers has 1 entry called docks, so now a df called 'docks' will be created\nfor(l in layers$name){\n  message(\"Reading layer: \", l)\n  assign(l, st_read(file.path(unzip_dir, \"floating_infrastructure-docks.gdb\"), layer = l, quiet = TRUE))\n}\n```\n:::\n\n\n\n\n### Map the data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Note that the coordinate reference system of these two layers are different\ninvisible(st_crs(docks)) # NAD 83\ninvisible(st_crs(coast)) # WGS 84\n\n# To plot with ggplot, one of them has to be reprojected. I've transformed the docks CRS to match the coastline CRS \ndocks = st_transform(docks, st_crs(coast))\n\n# Redefine the bounds of the layer of interest\nboundsDocks = st_bbox(docks)\n\n# Make a map of the docks\nggplot()+\n  geom_sf(data = coast, fill = \"lightgrey\")+\n  geom_sf(data = docks, size = 3.5, pch = 21, aes(fill = region), alpha = 0.65)+\n  coord_sf(\n    xlim = c(boundsDocks[\"xmin\"], boundsDocks[\"xmax\"]),\n    ylim = c(boundsDocks[\"ymin\"], boundsDocks[\"ymax\"])\n  ) +\n  scale_fill_discrete(name = \"Region\")+\n  theme_bw()\n```\n:::\n\n\n\n\n## Plotting raster data\n\nAn example is shown here for accessing and plotting raster data stored in a geodatabase. You can follow the example in the [Maritimes tutorial](https://github.com/AtlanticR/R_Git_Support/blob/main/open_data.Rmd) for accessing raster data from tiff files, if you are interested.\n\nThe example I'm using is from the [recreational vessel traffic model on the BC coast](https://open.canada.ca/data/dataset/fed5f00f-7b17-4ac2-95d6-f1a73858dac0).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Follow steps above to create a temporary folder to download & extract geodatabase info\ntemp_dir = tempdir()\nzip_file = file.path(temp_dir, \"bc_boating_model.zip\")\nunzip_dir = file.path(temp_dir, \"bc_boating_data\")\n\n# Download the dataset zip file. To get the correct link, follow the same steps as in the Pacific Recreational Fishery Salmon Head Depots example above, but with the \"FDGB/GDB\" item in Data and resources\ndownload.file(\n  url = \"https://api-proxy.edh-cde.dfo-mpo.gc.ca/catalogue/records/fed5f00f-7b17-4ac2-95d6-f1a73858dac0/attachments/Recreational_Boating_Data_Model.gdb.zip\",\n  destfile = zip_file,\n  mode = \"wb\"\n)\n\n# Unzip the contents\ndir.create(unzip_dir, showWarnings = FALSE)\nunzip(zip_file, exdir = unzip_dir)\n\n# List the file names you just downloaded \nboat_file = list.files(unzip_dir, full.names = TRUE)\n```\n:::\n\n\n\n\n## Mapping the survey effort data with `ggplot`\n\nUnfortunately, raster data in this format cannot be directly mapped with `ggplot`. But, you can convert it to a data frame and keep the coordinate positions.\n\nIf you read through [the metadata](https://egisp.dfo-mpo.gc.ca/arcgis/rest/services/open_data_donnees_ouvertes/recreational_vessel_traffic_model_for_british_columbia/MapServer), you'll see that that many types of data are available in this geodatabase (e.g., point data, raster, vector grid). The data being plotted in this example below is the *surveyeffort* raster dataset, which is specified using the `sub` argument in the `rast()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Turn the \"survey effort\" data into raster format\nsurveyRast = rast(boat_file, sub = \"surveyeffort\")\n\n# Use the project function to project to WGS 84 (i.e., to match the CRS of the coastline file)\nrast_proj = project(surveyRast, coast)\n\n# Convert it to a dataframe. Keep the coordinate info\nrast_df = as.data.frame(rast_proj, xy = TRUE) \n\n# Get the bounds for this. Using different code than above, since this is a regular data frame \nboundsRast = with(rast_df, c(xmin = min(x), xmax = max(x), ymin = min(y), ymax = max(y)))\n\n# Plot it with geom_tile and add the coast data as well\nggplot()+\n  geom_tile(data = rast_df, aes(x=x, y=y, fill = Recreational_Boating_Data_Model)) +\n  geom_sf(data = coast, fill = \"lightgrey\")+\n  scale_fill_viridis_c(option = \"magma\")+\n  coord_sf(xlim = c(boundsRast[\"xmin\"], boundsRast[\"xmax\"]),\n                ylim = c(boundsRast[\"ymin\"], boundsRast[\"ymax\"]))+\n  labs(x = NULL, y = NULL)+\n  theme_bw()\n```\n:::\n\n\n\n\n### Making Leaflet Maps\n\n[Leaflet maps](https://rstudio.github.io/leaflet/) are interactive maps that can be a great way to explore data. Leaflet maps can also be great for point data, since you can create [popup labels](https://rstudio.github.io/leaflet/articles/popups.html) where you can click and view your attribute data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert raster to leaflet-compatible format\npal = colorNumeric(palette = \"magma\", domain = values(rast_proj), na.color = \"transparent\")\n\n# Create leaflet map\nleaflet() %>%\n  addProviderTiles(providers$Esri.OceanBasemap) %>%\n  addRasterImage(rast_proj, colors = pal, opacity = 0.7, project = T) %>%\n  addLegend(pal = pal, values = values(rast_proj),\n            title = \"Survey Effort\",\n            position = \"bottomright\")\n```\n:::\n\n\n\n\n## Using `ckanr` to build more robust code\n\nSometimes, IT needs to upgrade server hardware or software, which can result in changes to the ArcGIS REST service URLs (i.e., the portion like this: *https://egisp.dfo-mpo.gc.ca/arcgis/rest/services*). However, the Universally Unique Identifier (UUID) associated with each dataset remains unchanged.\n\nIn the Open Data portal, the UUID is the final part of the URL after \"dataset\". For example, in the Pacific Recreational Salmon Head Depots dataset *(https://open.canada.ca/data/dataset/3cc03bbf-d59f-4812-996e-ddc52e0ba99e)*, the UUID is *3cc03bbf-d59f-4812-996e-ddc52e0ba99e*.\n\nTo make our script more robust, we can use the CKAN API. CKAN is a data management system that supports publishing, sharing, and discovering datasets. The ckanr package in R allows us to interact with CKAN-based portals, such as Open Data. You can use the `ckanr_setup()` function to establish a connection.\n\nInstead of hardcoding the ArcGIS REST URL in our script (which may change) we can use the CKAN API to reference the stable UUID. This allows us to dynamically retrieve the current ArcGIS REST URL associated with that UUID, ensuring our code remains functional even if updates occur.\n\n### Downloading data\n\nWe'll use the [Pacific Recreational Fishery Salmon Head Depots](https://open.canada.ca/data/dataset/3cc03bbf-d59f-4812-996e-ddc52e0ba99e) data as an example. We can use the `ckanr` package to extract the ArcGIS REST URL by referencing the UUID. This may seem like an extra step while you're writing your code, but it will save you time in the long run if the URLs change (it can happen!!)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nckanr_setup(\"https://open.canada.ca/data\")\nuuid = \"3cc03bbf-d59f-4812-996e-ddc52e0ba99e\"\npkg = ckanr::package_show(uuid)\nresources = pkg$resources\ndf_resources = as.data.frame(do.call(rbind, resources))\n\n# Now you can grab the correct ESRI Rest URL (\"url\"). Make sure to search for that format, and also specify you want the English (\"En\") version and not French\nsalmon_url = unlist(df_resources[df_resources$format == \"ESRI REST\" & sapply(df_resources$language, function(x) \"en\" %in% x), \"url\"])\n```\n:::\n\n\n\n\n### Searching for data\n\nYou can also use the `ckanr` package to search for data using the `package_search()` function. You can use the `q` argument to search for key words, and the `fq` argument to specify file types.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nckanr_setup(\"https://open.canada.ca/data\")\nsearch_results = package_search(q = \"Pacific salmon\")\nsearch_results # Note that UUID also shows up here after the <CKAN Package> text\n\n# You  can also search specifically for spatial data (e.g., shapefiles, geodatabases, etc.) by specifying the fq argument\nsearch_results = package_search(\n  q = \"Pacific salmon\",\n  fq = 'res_format:(SHP OR GDB OR GeoJSON OR KML OR CSV)' # CSVs sometimes contain spatial data, sometimes not\n)\n```\n:::\n",
    "supporting": [
      "openGovernmentPortalR_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}